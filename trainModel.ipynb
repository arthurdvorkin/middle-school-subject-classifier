{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:19:59.786672Z",
     "start_time": "2024-03-24T21:19:59.783553Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 19:57:31.771790: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-28 19:57:31.814385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "from subjects import label2id, id2label\n",
    "from sklearn.metrics import precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:20:00.402714Z",
     "start_time": "2024-03-24T21:19:59.786865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'distilbert/distilbert-base-uncased'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=8, id2label=id2label, label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:20:04.606074Z",
     "start_time": "2024-03-24T21:20:00.404615Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"train_dataset_1.csv\", \"validation\": \"validation_dataset_1.csv\"})\n",
    "test_dataset = load_dataset(\"csv\", data_files={\"test\":\"test_dataset_1.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:20:04.857107Z",
     "start_time": "2024-03-24T21:20:04.723812Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(data_to_tokenize):\n",
    "    text = data_to_tokenize[\"text\"]\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "    \n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tester_tokenized_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:20:05.830729Z",
     "start_time": "2024-03-24T21:20:04.866095Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels),\n",
    "            \"f1\" : f1.compute(predictions=predictions, references=labels, average=\"weighted\"),\n",
    "           }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:20:06.027944Z",
     "start_time": "2024-03-24T21:20:06.001504Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", # sequence classification\n",
    "                        r=4, # intrinsic rank of trainable weight matrix\n",
    "                        lora_alpha=32, # this is like a learning rate\n",
    "                        lora_dropout=0.1, # probablity of dropout\n",
    "                        target_modules = ['q_lin']) # we apply lora to query layer only\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 8\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.025,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T21:31:01.386880Z",
     "start_time": "2024-03-24T21:20:06.031314Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Test Metrics\n",
      "-----------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries Per Second: : 532.519\n",
      "Accuracy: 0.1399548532731377\n",
      "\n",
      "Percision per class\n",
      "Math: 0.0\n",
      "Science: 0.36363636363636365\n",
      "Language: 0.13707451701931922\n",
      "Physical Education: 0.0\n",
      "Social Studies: 0.0\n",
      "Health: 0.0\n",
      "Computers: 0.0\n",
      "Leadership: 0.0\n",
      "\n",
      "Recall per class\n",
      "Math: 0.0\n",
      "Science: 0.04067796610169491\n",
      "Language: 1.0\n",
      "Physical Education: 0.0\n",
      "Social Studies: 0.0\n",
      "Health: 0.0\n",
      "Computers: 0.0\n",
      "Leadership: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_test_set(trainer_obj):\n",
    "    test_res = trainer_obj.predict(tester_tokenized_dataset[\"test\"])\n",
    "    test_preds = np.argmax(test_res.predictions, axis=1)\n",
    "    test_labels = test_res.label_ids\n",
    "    \n",
    "    precision = precision_score(test_labels, test_preds, average=None)\n",
    "    reacall = recall_score(test_labels, test_preds, average=None)\n",
    "    print(f\"Queries Per Second: : {test_res.metrics['test_samples_per_second']}\")\n",
    "    print(f\"Accuracy: {test_res.metrics['test_accuracy']['accuracy']}\")\n",
    "    print(\"\\nPercision per class\")\n",
    "    for index, each_subject in enumerate(id2label):\n",
    "        print(f\"{id2label[each_subject]}: {precision[index]}\")\n",
    "    print(\"\\nRecall per class\")\n",
    "    for index, each_subject in enumerate(id2label):\n",
    "        print(f\"{id2label[each_subject]}: {reacall[index]}\")\n",
    "print(\"Base Model Test Metrics\")\n",
    "print(\"-----------------------\")\n",
    "\n",
    "run_test_set(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35432' max='35432' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35432/35432 09:12, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.221021</td>\n",
       "      <td>{'accuracy': 0.95483288166215}</td>\n",
       "      <td>{'f1': 0.954845659695672}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.234417</td>\n",
       "      <td>{'accuracy': 0.9561878952122854}</td>\n",
       "      <td>{'f1': 0.9563375370779424}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.185548</td>\n",
       "      <td>{'accuracy': 0.9697380307136405}</td>\n",
       "      <td>{'f1': 0.9697921271737132}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.161759</td>\n",
       "      <td>{'accuracy': 0.9751580849141824}</td>\n",
       "      <td>{'f1': 0.9751018872206434}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.174551</td>\n",
       "      <td>{'accuracy': 0.975609756097561}</td>\n",
       "      <td>{'f1': 0.9755642047287072}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.151179</td>\n",
       "      <td>{'accuracy': 0.979223125564589}</td>\n",
       "      <td>{'f1': 0.9792226762516094}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.145422</td>\n",
       "      <td>{'accuracy': 0.9805781391147245}</td>\n",
       "      <td>{'f1': 0.9805558656038241}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.142870</td>\n",
       "      <td>{'accuracy': 0.981029810298103}</td>\n",
       "      <td>{'f1': 0.9810119008459938}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'accuracy': 0.95483288166215}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.954845659695672}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9561878952122854}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9563375370779424}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9697380307136405}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9697921271737132}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9751580849141824}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9751018872206434}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.975609756097561}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9755642047287072}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.979223125564589}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9792226762516094}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.9805781391147245}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9805558656038241}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.981029810298103}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.9810119008459938}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35432, training_loss=0.1648490309419199, metrics={'train_runtime': 552.3501, 'train_samples_per_second': 256.576, 'train_steps_per_second': 64.148, 'total_flos': 4265303822740800.0, 'train_loss': 0.1648490309419199, 'epoch': 8.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Fine Tuning Test Metrics\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries Per Second: : 608.236\n",
      "Accuracy: 0.9769751693002258\n",
      "\n",
      "Percision per class\n",
      "Math: 0.9938650306748467\n",
      "Science: 0.9795918367346939\n",
      "Language: 0.9736842105263158\n",
      "Physical Education: 0.9856459330143541\n",
      "Social Studies: 0.9935691318327974\n",
      "Health: 0.9642857142857143\n",
      "Computers: 0.9495798319327731\n",
      "Leadership: 0.9688888888888889\n",
      "\n",
      "Recall per class\n",
      "Math: 0.9938650306748467\n",
      "Science: 0.976271186440678\n",
      "Language: 0.9932885906040269\n",
      "Physical Education: 0.9809523809523809\n",
      "Social Studies: 0.9809523809523809\n",
      "Health: 0.9737704918032787\n",
      "Computers: 0.9783549783549783\n",
      "Leadership: 0.9276595744680851\n"
     ]
    }
   ],
   "source": [
    "print(\"Post Fine Tuning Test Metrics\")\n",
    "print(\"-----------------------------\")\n",
    "run_test_set(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "text_list = [\"how much space the oranges need by themselves, what is  the remaining space, determine how many equal spaces you have between the oranges\",\" how much space the oranges need by themselves, what is  the remaining space, determine how many equal spaces you have between the oranges\",\n",
    "\"Who is Alexander the great?\", \"Preventing heart attacks can be done by many methods\", \"is a student-centered cultural anthropology mini textbook built with an equity lens. We are excited to share this with you all. This book attempts to address the lack of current, reliable, and relevant resources for introductory anthropology courses that center equity and anti-racism.\",\n",
    "\"How would you describe ?\", \"What is the importance of cells\", \"In what year was Armenia invdaded?\", \"Matter can change its state under different conditions. We have solids, like ice and rocks, which have a definite shape and volume. Liquids, such as water and juice, take the shape of their container but maintain a constant volume. Gases, like the air we breathe, have neither a definite shape nor volume and fill the space they occupy.\", \"The cradle of civilization was in the fertile valleys of rivers like the Tigris and Euphrates in Mesopotamia, the Nile in Egypt, the Indus in the Indian subcontinent, and the Yellow River in China. These early civilizations developed complex societies, writing systems, and technologies that shaped the course of history.\"]\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\")\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"saved-model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
